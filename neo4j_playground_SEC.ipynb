{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "967a0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from termcolor import cprint\n",
    "import ollama\n",
    "import requests\n",
    "from typing import Literal\n",
    "\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3edab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mConnecting to Neo4j at bolt://localhost:7687 with user neo4j and password test1234\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # Load local environment variables\n",
    "\n",
    "URI = \"bolt://localhost:\" + os.environ.get(\"URI_PORT\")\n",
    "NEO4J_USER = os.environ.get(\"NEO4J_USER\")\n",
    "NEO4J_PWD = os.environ.get(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DB = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")    # ðŸ‘ˆ choose DB here\n",
    "EMBED_MODEL = \"nomic-embed-text:latest\"\n",
    "\n",
    "cprint(f\"Connecting to Neo4j at {URI} with user {NEO4J_USER} and password {NEO4J_PWD}\", \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a30c6732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item1 from ./data/form10k/0000950170-23-027948.json\n",
      "\titem1 splitted into 254 chunks\n",
      "Processing item1a from ./data/form10k/0000950170-23-027948.json\n",
      "\titem1a splitted into 1 chunks\n",
      "Processing item7 from ./data/form10k/0000950170-23-027948.json\n",
      "\titem7 splitted into 1 chunks\n",
      "Processing item7a from ./data/form10k/0000950170-23-027948.json\n",
      "\titem7a splitted into 1 chunks\n"
     ]
    }
   ],
   "source": [
    "first_file_name = \"./data/form10k/0000950170-23-027948.json\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "def split_form10k_data_from_file(file):\n",
    "    \n",
    "    chunks_with_metadata = [] # accumlate chunk records\n",
    "    \n",
    "    data = json.load(open(file)) # open the json file\n",
    "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
    "        \n",
    "        print(f'Processing {item} from {file}') \n",
    "        \n",
    "        item_text_chunks = text_splitter.split_text(data[item]) # split the text into chunks\n",
    "        \n",
    "        chunk_seq_id = 0\n",
    "        for chunk in item_text_chunks: # only take the first 20 chunks\n",
    "            \n",
    "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "            \n",
    "            # finally, construct a record with metadata and the chunk text\n",
    "            chunks_with_metadata.append({\n",
    "                'text': chunk, \n",
    "                # metadata from looping...\n",
    "                'f10kItem': item,\n",
    "                'chunkSeqId': chunk_seq_id,\n",
    "                # constructed metadata...\n",
    "                'formId': f'{form_id}', # pulled from the filename\n",
    "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
    "                # metadata from file...\n",
    "                'names': data['names'],\n",
    "                'cik': data['cik'],\n",
    "                'cusip6': data['cusip6'],\n",
    "                'source': data['source'],\n",
    "            })\n",
    "            \n",
    "            chunk_seq_id += 1\n",
    "            \n",
    "        print(f'\\t{item} splitted into {chunk_seq_id} chunks')\n",
    "        \n",
    "    return chunks_with_metadata\n",
    "\n",
    "\n",
    "chunks_dicts = split_form10k_data_from_file(first_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54a22804",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(uri=URI, auth=(NEO4J_USER, NEO4J_PWD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf737a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "== Connected to Neo4j database: neo4j\u001b[0m\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0000\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0001\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0002\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0003\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0004\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0005\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0006\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0007\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0008\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0009\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0010\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0011\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0012\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0013\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0014\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0015\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0016\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0017\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0018\n",
      "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0019\n",
      "Created 20 nodes\n"
     ]
    }
   ],
   "source": [
    "wipe_at_init = True # delete everything at the start \n",
    "\n",
    "with driver.session(database=NEO4J_DB) as session:\n",
    "    dbinfo = session.run(\"CALL db.info()\").single()\n",
    "    cprint(f\"\\n== Connected to Neo4j database: {dbinfo['name']}\", \"green\")\n",
    "    session.run(\"\"\"\n",
    "    CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "        FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "    \"\"\")\n",
    "    node_count = 0\n",
    "\n",
    "    for chunk_dict in chunks_dicts[:20]:\n",
    "        print(f\"Creating `:Chunk` node for chunk ID {chunk_dict['chunkId']}\")\n",
    "        session.run(\"\"\"MERGE(c:Chunk {chunkId: $chunkParamDict.chunkId})\n",
    "            ON CREATE SET \n",
    "                c.names = $chunkParamDict.names,\n",
    "                c.formId = $chunkParamDict.formId, \n",
    "                c.cik = $chunkParamDict.cik, \n",
    "                c.cusip6 = $chunkParamDict.cusip6, \n",
    "                c.source = $chunkParamDict.source, \n",
    "                c.f10kItem = $chunkParamDict.f10kItem, \n",
    "                c.chunkSeqId = $chunkParamDict.chunkSeqId, \n",
    "                c.text = $chunkParamDict.text\n",
    "        RETURN c\"\"\", \n",
    "        parameters={\n",
    "            'chunkParamDict': chunk_dict\n",
    "            }\n",
    "        )\n",
    "        node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce3936ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Found 1 vector index entries.\u001b[0m\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "{'entityType': 'NODE',\n",
      " 'id': 5,\n",
      " 'indexProvider': 'vector-2.0',\n",
      " 'labelsOrTypes': ['Chunk'],\n",
      " 'lastRead': None,\n",
      " 'name': 'form_10k_chunks',\n",
      " 'owningConstraint': None,\n",
      " 'populationPercent': 0.0,\n",
      " 'properties': ['text_emb'],\n",
      " 'readCount': None,\n",
      " 'state': 'POPULATING',\n",
      " 'type': 'VECTOR'}\n",
      "\u001b[32m\n",
      "Generating embeddings for (n:Chunk) on n.text\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with driver.session(database=NEO4J_DB) as session:\n",
    "    \n",
    "    # Create vector index\n",
    "    session.run(\"\"\"\n",
    "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "         FOR (c:Chunk) ON (c.text_emb) \n",
    "         OPTIONS { indexConfig: { \n",
    "         `vector.dimensions`: 768, `vector.similarity_function`: 'cosine' \n",
    "         } }\n",
    "         \"\"\")\n",
    "    \n",
    "    # Show created vector indexes\n",
    "    results = session.run(\"SHOW VECTOR INDEXES\")\n",
    "    idx = list(results)\n",
    "    cprint(f\"\\nFound {len(idx)} vector index entries.\", \"green\")\n",
    "    for r in idx:\n",
    "        cprint(\"-\"*20,\"green\")\n",
    "        pprint(dict(r))\n",
    "        \n",
    "    cprint(f\"\\nGenerating embeddings for (n:Chunk) on n.text\", \"green\")\n",
    "    records = list(session.run(f\"\"\"\n",
    "        MATCH (n:Chunk)\n",
    "        WHERE n.text IS NOT NULL AND n.text <> ''\n",
    "        AND n.text_emb IS NULL\n",
    "        RETURN n.chunkId AS chunkId, n.text AS txt\n",
    "        \"\"\"))\n",
    "    for r in records:\n",
    "        vec = ollama.embed(model=\"nomic-embed-text\", input=r[\"txt\"])[\"embeddings\"][0]\n",
    "        session.run(\n",
    "            f\"\"\"\n",
    "            MATCH (n:Chunk {{chunkId: $chunkId}})\n",
    "            SET n.text_emb = $vec\n",
    "            \"\"\",\n",
    "            chunkId=r[\"chunkId\"], vec=vec\n",
    "        )\n",
    "        print(f\"  text: {r['txt']}\\n  vec: {vec[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eabc8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From user query/question to question embedding\n",
    "def create_question_embedding(question:str):\n",
    "    cprint(f\"\\nGenerating embeddings for question '{question}'\", \"green\")\n",
    "    vec = ollama.embed(model=\"nomic-embed-text\", input=question)[\"embeddings\"][0] \n",
    "    print(f\"  text: {question}\\n  vec: {vec[:10]}\\n\")\n",
    "    return vec\n",
    "  \n",
    "# From query/question to cypher query language (cql) TODO\n",
    "def create_question_cql(question:str):\n",
    "    cql_query = \"\"\n",
    "    #cql_query = \"MATCH (person)-[:KNOWS]-(:Person {name:'Cristina'})\" \n",
    "    return cql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e717ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Generating embeddings for question 'In a single sentence, tell me about Netapp.'\u001b[0m\n",
      "  text: In a single sentence, tell me about Netapp.\n",
      "  vec: [0.023942923, 0.06676347, -0.123865075, -0.024302177, 0.07153227, -0.02668256, 0.007319313, -0.033634715, -0.017225634, -0.0583832]\n",
      "\n",
      "<Record score=0.8422031402587891 text='â€¢\\nNetApp Keystone is our pay-as-you-grow, storage-as-a-service (STaaS) offering that delivers a seamless hybrid cloud experience for those preferring operating expense consumption models to upfront capital expense or leasing. With a unified management console and monthly bill for both on-premises and cloud data storage services, Keystone lets organizations provision and monitor, and even move storage spend across their hybrid cloud environment for financial and operational flexibility. \\n\\n\\nâ€¢\\nNetApp Global Support supplies systems, processes, and people wherever needed to provide continuous operation in complex and critical environments, with an emphasis on proactive and preemptive technology support for operational continuity across the NetApp hybrid cloud. Personalized support options provide actionable intelligence to resolve problems faster, reduce downtime, and optimize performance of the entire NetApp ecosystem.\\n\\n\\nSales, Principal Markets, and Distribution Channels\\n\\n\\nWe market and sell our products and services in numerous countries throughout the world.  Our sales efforts are organized around the evolving needs of our current and targeted customers, and our marketing initiatives reflect this focus. NetApp uses a multichannel distribution strategy. We sell our products, solutions and services to end-user business customers and service providers through a direct sales force and an ecosystem of partners, including the leading cloud providers. Our marketing is focused on building our brand reputation, creating market awareness, communicating customer advantages and generating demand for our sales force and channel partners.\\n\\n\\n8'>\n",
      "<Record score=0.8379645347595215 text='>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term â€˜evolved cloudâ€™, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organizationâ€™s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organizationâ€™s hybrid multicloud environment are:\\n\\n\\nâ€¢\\nOperational simplicity: NetAppâ€™s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\nâ€¢\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.'>\n",
      "<Record score=0.8369369506835938 text=\"â€¢\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.\\n\\n\\nâ€¢\\nCyber resilience: NetApp unifies monitoring, data protection, security, governance, and compliance for total cyber resilience - with consistency and automation across environments. \\n\\n\\nâ€¢\\nContinuous operations: NetApp uses AI-driven automation for continuous optimization to service applications and store stateless and stateful applications at the lowest possible costs.\\n\\n\\nâ€¢\\nSustainability: NetApp has industry-leading tools to audit consumption, locate waste, and set guardrails to stop overprovisioning.\\n\\n\\nProduct, Solutions and Services Portfolio\\n \\n\\n\\nNetApp's portfolio of cloud services and storage infrastructure is powered by intelligent data management software. Our operations are organized into two segments: Hybrid Cloud and Public Cloud.\\n\\n\\n \\n\\n\\nHybrid Cloud\\n\\n\\nHybrid Cloud \\noffers a portfolio of storage management and infrastructure solutions that help customers recast their traditional data centers into modern data centers with the power of the cloud. Our hybrid cloud portfolio is designed to operate with public clouds to unlock the potential of hybrid, multi-cloud operations. We offer a broad portfolio of cloud-connected all-flash, hybrid-flash, and object storage systems, powered by intelligent data management software. Hybrid Cloud is composed of software, hardware, and related support, as well as professional and other services.\\n\\n\\nIntelligent data management software\">\n",
      "<Record score=0.8351221084594727 text='8\\n\\n\\n\\n\\n\\xa0\\n\\n\\nOur diversified customer base spans industry segments and vertical markets such as energy, financial services, government, technology, internet, life sciences, healthcare services, manufacturing, media, entertainment, animation, video postproduction and telecommunications. NetApp focuses primarily on the enterprise storage and data management, cloud storage and cloud operations markets. We design our products to meet the evolving requirements of a hybrid, multicloud world, driven by digital transformation and cloud initiatives.\\n\\n\\nOur partnerships with the industryâ€™s leading cloud, infrastructure, consulting, application, and reseller partners are created with one goal in mind: the success of our customers. Global enterprises, local businesses, and government installations look to NetApp and our ecosystem of partners to help maximize the business value of their IT and cloud investments.\\n\\n\\nWe work with a wide range of partners for our customers, including technology partners, value-added resellers, system integrators, OEMs, service providers and distributors. During fiscal 2023, sales through our indirect channels represented 78% of our net revenues. Our global partner ecosystem is critical to NetAppâ€™s growth and success. We are continually strengthening existing partnerships and investing in new ones to ensure we are meeting the evolving needs of our customers.'>\n",
      "<Record score=0.827949047088623 text='Harvinder S. Bhela\\n joined NetApp in January 2022 as executive vice president and chief product officer. He is responsible for leading NetAppâ€™s product and engineering teams and building our storage and data services products. Before joining NetApp, Mr. Bhela spent 25 years at Microsoft where he held multiple executive leadership positions. Most recently he served as corporate vice president of the Microsoft 365 Security, Compliance and Management business. Mr. Bhela holds a Bachelor of Engineering from the University of Mumbai and a Master of Science in Computer Science from the University of Minnesota.\\n\\n\\nElizabeth M. Oâ€™Callahan \\nwas appointed executive vice president, chief legal officer, and corporate secretary in January 2022. Ms. Oâ€™Callahan joined NetApp in 2013, and prior to her appointment as chief legal officer, Ms. Oâ€™Callahan served as senior vice president and general counsel from May 2021 to December 2021, as vice president and deputy general counsel from May 2020 to April 2021, and as vice president, corporate legal from October 2013 to April 2020.  Ms. Oâ€™Callahan has over 20 years of experience advising technology companies on a variety of matters, including corporate governance, securities law, mergers and acquisitions, capital markets transactions, corporate compliance and ethics, data privacy, intellectual property, and litigation. Before joining NetApp, Ms. Oâ€™Callahan served in a senior legal role at Xilinx (since acquired by AMD). She began her legal career in private practice in Silicon Valley specializing in corporate law and business litigation. Ms. Oâ€™Callahan holds a bachelorâ€™s degree from the University of California at Los Angeles and a J.D. from Santa Clara University.\\n\\n\\nAdditional Information'>\n",
      "<Record score=0.8208804130554199 text=\"Intelligent data management software\\n\\n\\nNetApp ONTAP\\n software is our foundational technology that underpins NetApp's critical storage solutions in the data center and the cloud. ONTAP includes various data management and protection features and capabilities, including automatic ransomware protection against cyber-attacks, built-in data transport features, and storage efficiency capabilities. ONTAP provides the flexibility to design and deploy a storage environment across the broadest range of architectures â€“ from on-premises, hybrid, public, and private clouds. It can be used in NAS, SAN, object environments, and software-defined storage (SDS) situations.\\n\\n\\nData integrity and safety are at the heart of any companyâ€™s data center. With NetAppâ€™s extensive software tools and utilities, customers can realize their business continuity goals with time, costs, and personnel savings. With \\nNetApp Snapshot\\n, customers can create and manage point-in-time file system copies with no performance impact and minimal storage consumption. This is important for continuous data protection of information in read-only, static, and immutable form. \\nNetApp SnapCenter Backup Management\\n \\ns\\noftware\\n \\nis designed to deliver high-performance backup and recovery for database and application workloads hosted on ONTAP storage. \\nNetApp SnapMirror Data Replication\\n software can replicate data at high speeds across environments. SnapMirror delivers\\n \\n\\n\\n6\\n\\n\\n\\n\\n\\xa0\\n\\n\\nrobust data management capabilities for virtualization, protecting critical data while providing the flexibility to move data between locations and storage tiers, including cloud service providers. \\nNetApp SnapLock Data Compliance \\nsoftware delivers high-performance disk-based data permanence for HDD and SSD deployments.\">\n",
      "<Record score=0.82061767578125 text='Cloud storage, data services, and software\\n\\n\\nThe NetApp Cloud Volumes Platform is an integrated collection of cloud storage infrastructure and data services. The platform is anchored by \\nNetApp Cloud Volumes ONTAP\\n, a cloud-based software for customers who wish to manage their own cloud storage infrastructure. It is based on the same ONTAP data management software that underpins our storage infrastructure offerings. Fully managed cloud storage offerings are available natively on Microsoft Azure as \\nAzure NetApp Files\\n, on AWS as \\nAmazon FSx for NetApp ONTAP\\n, and on Google Cloud as \\nNetApp Cloud Volumes Service for Google Cloud.\\n \\n\\n\\nManageability\\n\\n\\nAt the heart of our public cloud storage and data service offerings is \\nNetApp\\n \\nBlueXP\\n. BlueXP is a unified control plane that enables customers to manage their entire data landscape through one single, SaaS-delivered point of control. NetApp BlueXP combines storage and data services via its unified control plane to change how hybrid, multicloud environments are managed, optimized, and controlled. An intuitive interface and powerful automation help decrease resource waste, complexity, and the risk of managing diverse environments. It brings customers operational simplicity in a complex world. Within BlueXP are standard and optional capabilities (services) which allow customers to control their data and operations.\\n\\n\\n7'>\n",
      "<Record score=0.8156943321228027 text=\"Another cloud operations service is \\nInstaclustr\\n, our platform that provides fully managed open-source databases, pipelines, and workflow applications delivered as a service. Instaclustr helps organizations deliver cloud-native applications at scale by operating and supporting their data infrastructure through its SaaS platform for those designing and building around open-source technologies.\\n \\n\\n\\nProfessional and Support Services\\n\\n\\nNetApp and our certified services partners offer a comprehensive portfolio of assessment, design, implementation, migration, and proactive support services to help customers optimize the performance and efficiency of their on-premises and hybrid multicloud storage environments. Our portfolio of offerings include strategic consulting, professional, managed, and support services.\\n \\n\\n\\nâ€¢\\nNetApp strategic consulting services provide executive-level, high-touch consulting engagements to help organizations facilitate the alignment of their business and technology goals. Our proven expertise can help organizations define long-term data fabric strategies and operations models to drive IT initiatives for digital transformation.\\n \\n\\n\\nâ€¢\\nNetApp Professional Services provide the expertise to mitigate risk and streamline the design, implementation, migration, and integration of NetApp hybrid cloud solutions to realize the business benefits of new technology investments faster. Highly skilled services experts help enable secure, optimized environments that deliver the consistent, high-quality outcomes customers expect from the start.\\n \\n\\n\\nâ€¢\\nNetApp Managed Services optimize performance and efficiency in hybrid cloud and on-premises environments. Our NetApp experts use proven methodology and best practices to monitor, administer, operate, and optimize customer environments so their organization's IT staff is free to focus on initiatives to move the business forward.\">\n",
      "<Record score=0.8144564628601074 text='NetApp Astra (Astra)\\n is a fully managed application-aware data management service built for emerging Kubernetes workloads container infrastructures. Astra allows organizations to protect, recover, and move applications deployed on Kubernetes with no software to download, install, manage, or upgrade.\\n \\n\\n\\nStorage infrastructure\\n \\n\\n\\nNetApp All-Flash FAS (AFF A-Series)\\n is a scale-out platform built for virtualized environments, combining low-latency performance via flash memory (also known as a solid-state storage disk) with best-in-class data management, built-in efficiencies, integrated data protection, multiprotocol support, and nondisruptive operations; cloud and on-premises. AFF A-Series, powered by ONTAP, allows customers to connect to clouds for more data services, data tiering, caching, and disaster recovery. The AFF A-Series has a portfolio of products designed for multiple markets and price/performance considerations, from smaller channel commercial market offerings to large-scale, global enterprises.\\n\\n\\nNetApp QLC-Flash FAS (AFF C-Series) \\nis NetAppâ€™s newest family of storage infrastructure solutions. AFF C-Series arrays are sustainable, scalable, and secure solutions for Tier 1 and Tier 2 applications. AFF C-series provides customers capacity flash performance and affordability, so that customers do not need to make compromises. The AFF C-Series is ideal for transitioning from hybrid/HDD to all-flash storage; running non-latency sensitive VMware database applications and file environments; and providing a solution for secondary storage targets for disaster recovery, backup, and tiering.\\n \\n\\n\\nNetApp Fabric Attached Storage (FAS)\\n series\\n \\nare high-volume, high-capacity data storage devices powered by NetApp ONTAP. NetApp FAS Storage Arrays provide customers with a balance of performance and capacity running either disk drives or hybrid-flash configurations. FAS systems are suitable for secondary storage targets for disaster recovery, backup, and tiering.'>\n",
      "<Record score=0.8134498596191406 text='NetApp E/EF series\\n is built for dedicated, high-bandwidth applications that need simple, fast SAN storage with enterprise-grade reliability. The E-Series is available as a hybrid-flash platform, while the EF-Series is all-flash. On the SANtricity storage operating system, the E/EF-Series storage appliances are designed for performance-sensitive workloads like real-time analytics, high performance computing, and databases.\\n \\n\\n\\nNetApp StorageGRID\\n is a software-defined object storage solution for large archives, media repositories, and web data stores. Using the industry-standard object APIs like the Amazon Simple Storage Service (S3), the StorageGRID solution, running on the ElementOS data management storage operating system, is provided as a NetApp-branded storage solution and as a software-defined solution on third-party hardware.\\n \\n\\n\\n\\xa0\\n\\n\\nPublic Cloud\\n\\n\\nPublic Cloud\\n offers a portfolio of products delivered primarily as-a-service, including related support. This portfolio includes cloud storage and data services and cloud operations services. Our enterprise-class solutions and services enable customers to control and manage storage in the cloud, consume high-performance storage services for primary workloads, and optimize cloud environments for cost and efficiency. These solutions and services are generally available on the leading public clouds, including Amazon AWS, Microsoft Azure, and Google Cloud Platform.\\n \\n\\n\\nCloud storage, data services, and software'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "def neo4j_node_vector_search(question, index_name):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  \n",
    "  with driver.session(database=NEO4J_DB) as session:\n",
    "      \n",
    "      top_k = 10\n",
    "      vector_search_query = f\"\"\"\n",
    "      CALL db.index.vector.queryNodes($index_name, $top_k, $question_embedding) \n",
    "      YIELD node, score\n",
    "      {create_question_cql(question)}\n",
    "      RETURN score, node.text AS text\n",
    "      \"\"\"\n",
    "  \n",
    "      res = session.run(\n",
    "        vector_search_query, \n",
    "        {\"index_name\": index_name, \n",
    "         \"top_k\": top_k,\n",
    "         \"question_embedding\": create_question_embedding(question),}\n",
    "        )\n",
    "      result = list(res)\n",
    "      \n",
    "  return result\n",
    "\n",
    "\n",
    "result = neo4j_node_vector_search(\n",
    "    'In a single sentence, tell me about Netapp.',\n",
    "    'form_10k_chunks'\n",
    ")\n",
    "\n",
    "for r in result:\n",
    "    print(dict(r))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
